{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cbt6VJ8gzd7-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from prophet import Prophet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this work we will need our 3 different sources of data:\n",
        "\n",
        "*   research from the field labeled on topics\n",
        "*   patents from the field labeled on topics\n",
        "*   overall financial data per country\n",
        "\n",
        "\n",
        "The topics were labeled using CLAUDE AI, and verified/shrinked by a **quantum expert** to only represent meaningful information and no repetition.\n"
      ],
      "metadata": {
        "id": "5xW_5LYpMPdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patents = pd.read_csv(\"patents_labeled.csv\")\n",
        "research = pd.read_csv(\"cleaned_final_data.csv\")\n",
        "financial = pd.read_csv(\"quantum_funding_with_all_countries.csv\", sep=\";\")"
      ],
      "metadata": {
        "id": "GUQWmWaYz1Nb"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Patents columns:\", patents.columns)\n",
        "print(\"Research columns:\", research.columns)\n",
        "print(\"Financial columns:\", financial.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvrIg82Q0goe",
        "outputId": "70d36e49-2d40-442d-df79-c6a7e628caf0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patents columns: Index(['#', 'Publication Year', 'Title', 'Abstract', 'Applicants', 'Inventors',\n",
            "       'Country', 'Label'],\n",
            "      dtype='object')\n",
            "Research columns: Index(['Authors', 'Title', 'Year', 'Cited by', 'Affiliations',\n",
            "       'Authors with affiliations', 'Abstract', 'Author_list', 'Country',\n",
            "       'Label'],\n",
            "      dtype='object')\n",
            "Financial columns: Index(['year', 'Armenia', 'Austria', 'Belgium', 'Bulgaria', 'Switzerland',\n",
            "       'Cyprus', 'Czech Republic', 'Germany', 'Denmark', 'Estonia', 'Greece',\n",
            "       'Spain', 'Finland', 'France', 'Croatia', 'Hungary', 'Ireland', 'Israel',\n",
            "       'Italy', 'Lithuania', 'Luxembourg', 'Latvia', 'Netherlands', 'Norway',\n",
            "       'Poland', 'Portugal', 'Romania', 'Serbia', 'Sweden', 'Slovenia',\n",
            "       'Slovakia', 'Turkey', 'Ukraine', 'United Kingdom', 'USA', 'Canada',\n",
            "       'Japan', 'China', 'South Korea', 'India', 'Australia', 'Singapore'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the **\"Year\"** collumn is not consitent for all the 3 different datasets we have. We will need first to solve this so we can aggregate data per year."
      ],
      "metadata": {
        "id": "kmoLTipaMCos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patents.rename(columns={\"Publication Year\": \"Year\"}, inplace=True)"
      ],
      "metadata": {
        "id": "Vy1xwGLN0nh3"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the financial data, things will be kept simple and we aggregate all the investted money per year, no matter the subfield of quantum."
      ],
      "metadata": {
        "id": "FD0S4WWOOAwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initially we have the year, and the collumns representing one country and entiry for that row, the amount of money invested from that country\n",
        "#we chnage this to have the amount as a separate collumn, country as only one collumn and the entires are the actual countries\n",
        "#it will look like year, country and count (value)\n",
        "financial_long = financial.melt(id_vars=\"year\", var_name=\"Country\", value_name=\"Count\")\n",
        "\n",
        "#we just convert this to numeric in case it wasnt already  - this dataset was made by Irene\n",
        "financial_long[\"Count\"] = pd.to_numeric(financial_long[\"Count\"], errors=\"coerce\")\n",
        "\n",
        "#as said we just group based per each year all investments from all countries\n",
        "financial_grouped = financial_long.groupby(\"year\", as_index=False)[\"Count\"].sum()\n",
        "#we just rename the collumns for clarity\n",
        "financial_grouped.rename(columns={\"year\": \"Year\", \"Count\": \"Financial\"}, inplace=True)"
      ],
      "metadata": {
        "id": "07-eXAeu00ii"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(financial_grouped[financial_grouped[\"Year\"] == 2017])\n",
        "#just to check ifall worked out\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgNjvjJr7Fv1",
        "outputId": "024c63e5-a046-4403-e4a8-f8fe562d5ce6"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year  Financial  Financial_normalized\n",
            "3  2017       6268              0.257953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to count all number of patents **per year**, **per specific label** so we can use it in the final combined formula. The idea will be that user can select his preferences based on the subtopic he wants to explore."
      ],
      "metadata": {
        "id": "tzlXhImgPAmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_per_label_per_year(df):\n",
        "    return df.groupby([\"Year\", \"Label\"]).size().reset_index(name=\"Count\")\n",
        "#the number of rows for each (Year, Label) pair so we count how many patents for each label.\n",
        "#this can be used as well for the research papers dataset\n",
        "\n",
        "\n",
        "#we just pply the same function because the initial data is organised the same\n",
        "patent_counts = count_per_label_per_year(patents)\n",
        "research_counts = count_per_label_per_year(research)\n"
      ],
      "metadata": {
        "id": "_tyfLMP00HLD"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to  **normlaize the data **  in the financial part so it lies between 0 and 1 rather than huge numbers."
      ],
      "metadata": {
        "id": "x8aJ2FC-QAaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#copy\n",
        "financial_grouped = financial_grouped.copy()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "#we take the new grouoped financial data and we normalize creating a new collumn\n",
        "financial_grouped[\"Financial_normalized\"] = scaler.fit_transform(financial_grouped[[\"Financial\"]])\n"
      ],
      "metadata": {
        "id": "fXImGcwH74MO"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will combine/merge the patent coutns per year and the research counts based on **year and label** and then merge this with the financial data based on year. We will left join so we keep all rows already existed from the first step I mwntioned."
      ],
      "metadata": {
        "id": "RW4sE5uSR0Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined = pd.merge(patent_counts, research_counts, on=[\"Year\", \"Label\"], how=\"outer\", suffixes=(\"_patents\", \"_research\"))\n",
        "combined = pd.merge(combined, financial_grouped[[\"Year\", \"Financial_normalized\"]], on=\"Year\", how=\"left\")\n",
        "\n",
        "#note here why left join and outer join\n",
        "#outher will keep all values we join on\n",
        "\n",
        "\n",
        "combined.fillna(0, inplace=True)\n",
        "\n",
        "#SAME NORMALIZATION FOR PATENTES AND RESEARCH TO MAKE THEM ON THE SAME SCALE.\n",
        "scaler = MinMaxScaler()\n",
        "combined[[\"Count_patents\", \"Count_research\"]] = scaler.fit_transform(\n",
        "    combined[[\"Count_patents\", \"Count_research\"]]\n",
        ")\n",
        "\n",
        "#we just rename back to financial to not keep any confusion\n",
        "combined.rename(columns={\"Financial_normalized\": \"Financial\"}, inplace=True)\n",
        "\n",
        "#IMPORTANT\n",
        "#WE WILL COMPUTE THE SCORES WITH THIS FORMULA BUT LATER IN THE APP THIS CAN BE PERSONALIZED.\n",
        "#HOWEVER I STRONLGY RECOMMED TO USE THIS, BECAUSE IT WAS ANALYZSED BASED ON HOW MUCH DATA IS AVALIABLE FOR EACH SECTION\n",
        "\n",
        "combined[\"WeightedScore\"] = (0.55 * combined[\"Count_patents\"] +0.35 * combined[\"Count_research\"] +0.1 * combined[\"Financial\"])\n"
      ],
      "metadata": {
        "id": "Fk64Gh9q7g8L"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from final data we just remove this 2 labels\n",
        "combined = combined[~combined[\"Label\"].isin([\"error\", \"invalid_label\"])].copy()\n",
        "\n",
        "invalid_labels = [\"error\", \"invalid_label\"]\n",
        "patents = patents[~patents[\"Label\"].isin(invalid_labels)].copy()\n",
        "research = research[~research[\"Label\"].isin(invalid_labels)].copy()\n"
      ],
      "metadata": {
        "id": "jio6T-bs6Rwm"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined.head(25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "NaMTgroZ6XiN",
        "outputId": "89b9f881-1a5d-4de2-8c8e-7b33cf8da29b"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Year                                Label  Count_patents  Count_research  \\\n",
              "0   2017                   quantum algorithms       0.029903        0.050718   \n",
              "1   2017                    quantum coherence       0.014604        0.038278   \n",
              "2   2017                quantum communication       0.047288        0.022010   \n",
              "3   2017                  quantum compilation       0.004868        0.006699   \n",
              "4   2017     quantum computational complexity       0.000000        0.005742   \n",
              "5   2017                    quantum computing       0.189152        0.211483   \n",
              "6   2017       quantum computing applications       0.223922        0.039234   \n",
              "7   2017        quantum computing foundations       0.000000        0.004785   \n",
              "8   2017  quantum computing hardware (hybrid)       0.106398        0.044019   \n",
              "9   2017             quantum computing theory       0.006259        0.152153   \n",
              "10  2017                      quantum control       0.059110        0.022010   \n",
              "11  2017                   quantum conversion       0.025730        0.000000   \n",
              "12  2017                 quantum cryptography       0.081363        0.044019   \n",
              "13  2017              quantum data structures       0.014604        0.000000   \n",
              "14  2017        quantum distributed computing       0.013213        0.002871   \n",
              "15  2017             quantum error correction       0.004868        0.073684   \n",
              "16  2017             quantum error mitigation       0.007650        0.001914   \n",
              "17  2017                     quantum hardware       0.173853        0.011483   \n",
              "18  2017             quantum image processing       0.064673        0.002871   \n",
              "19  2017           quantum information theory       0.001391        0.006699   \n",
              "20  2017                  quantum logic gates       0.007650        0.000000   \n",
              "21  2017             quantum machine learning       0.013213        0.007656   \n",
              "22  2017                    quantum metrology       0.000695        0.002871   \n",
              "23  2017                 quantum optimization       0.142559        0.050718   \n",
              "24  2017       quantum reinforcement learning       0.000695        0.000000   \n",
              "\n",
              "    Financial  WeightedScore  \n",
              "0    0.257953       0.059993  \n",
              "1    0.257953       0.047224  \n",
              "2    0.257953       0.059507  \n",
              "3    0.257953       0.030817  \n",
              "4    0.257953       0.027805  \n",
              "5    0.257953       0.203848  \n",
              "6    0.257953       0.162685  \n",
              "7    0.257953       0.027470  \n",
              "8    0.257953       0.099721  \n",
              "9    0.257953       0.082491  \n",
              "10   0.257953       0.066009  \n",
              "11   0.257953       0.039947  \n",
              "12   0.257953       0.085952  \n",
              "13   0.257953       0.033827  \n",
              "14   0.257953       0.034067  \n",
              "15   0.257953       0.054262  \n",
              "16   0.257953       0.030672  \n",
              "17   0.257953       0.125433  \n",
              "18   0.257953       0.062370  \n",
              "19   0.257953       0.028905  \n",
              "20   0.257953       0.030003  \n",
              "21   0.257953       0.035742  \n",
              "22   0.257953       0.027183  \n",
              "23   0.257953       0.121954  \n",
              "24   0.257953       0.026178  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4cf8129-94e2-4499-9b20-eae3f6247850\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Label</th>\n",
              "      <th>Count_patents</th>\n",
              "      <th>Count_research</th>\n",
              "      <th>Financial</th>\n",
              "      <th>WeightedScore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum algorithms</td>\n",
              "      <td>0.029903</td>\n",
              "      <td>0.050718</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.059993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum coherence</td>\n",
              "      <td>0.014604</td>\n",
              "      <td>0.038278</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.047224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum communication</td>\n",
              "      <td>0.047288</td>\n",
              "      <td>0.022010</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.059507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum compilation</td>\n",
              "      <td>0.004868</td>\n",
              "      <td>0.006699</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.030817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum computational complexity</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005742</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.027805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum computing</td>\n",
              "      <td>0.189152</td>\n",
              "      <td>0.211483</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.203848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum computing applications</td>\n",
              "      <td>0.223922</td>\n",
              "      <td>0.039234</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.162685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum computing foundations</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004785</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.027470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum computing hardware (hybrid)</td>\n",
              "      <td>0.106398</td>\n",
              "      <td>0.044019</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.099721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum computing theory</td>\n",
              "      <td>0.006259</td>\n",
              "      <td>0.152153</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.082491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum control</td>\n",
              "      <td>0.059110</td>\n",
              "      <td>0.022010</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.066009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum conversion</td>\n",
              "      <td>0.025730</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.039947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum cryptography</td>\n",
              "      <td>0.081363</td>\n",
              "      <td>0.044019</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.085952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum data structures</td>\n",
              "      <td>0.014604</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.033827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum distributed computing</td>\n",
              "      <td>0.013213</td>\n",
              "      <td>0.002871</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.034067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum error correction</td>\n",
              "      <td>0.004868</td>\n",
              "      <td>0.073684</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.054262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum error mitigation</td>\n",
              "      <td>0.007650</td>\n",
              "      <td>0.001914</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.030672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum hardware</td>\n",
              "      <td>0.173853</td>\n",
              "      <td>0.011483</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.125433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum image processing</td>\n",
              "      <td>0.064673</td>\n",
              "      <td>0.002871</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.062370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum information theory</td>\n",
              "      <td>0.001391</td>\n",
              "      <td>0.006699</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.028905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum logic gates</td>\n",
              "      <td>0.007650</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.030003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum machine learning</td>\n",
              "      <td>0.013213</td>\n",
              "      <td>0.007656</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.035742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum metrology</td>\n",
              "      <td>0.000695</td>\n",
              "      <td>0.002871</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.027183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum optimization</td>\n",
              "      <td>0.142559</td>\n",
              "      <td>0.050718</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.121954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2017</td>\n",
              "      <td>quantum reinforcement learning</td>\n",
              "      <td>0.000695</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.026178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4cf8129-94e2-4499-9b20-eae3f6247850')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4cf8129-94e2-4499-9b20-eae3f6247850 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4cf8129-94e2-4499-9b20-eae3f6247850');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1231b82b-047b-408d-9c7b-1aa8b1ba1b7d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1231b82b-047b-408d-9c7b-1aa8b1ba1b7d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1231b82b-047b-408d-9c7b-1aa8b1ba1b7d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined",
              "summary": "{\n  \"name\": \"combined\",\n  \"rows\": 344,\n  \"fields\": [\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2017,\n        \"max\": 2025,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          2024,\n          2018,\n          2022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"quantum thermodynamics\",\n          \"quantum fidelity estimation\",\n          \"quantum computational complexity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count_patents\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1492423033823282,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 178,\n        \"samples\": [\n          0.002086230876216968,\n          0.04242002781641168,\n          0.07440890125173852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count_research\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12487138560660392,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 139,\n        \"samples\": [\n          0.307177033492823,\n          0.016267942583732056,\n          0.08038277511961722\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Financial\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2114648550368088,\n        \"min\": 0.25795300218115974,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.6617556278036134,\n          0.5615868965801062,\n          0.5551257253384914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WeightedScore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12374008354031248,\n        \"min\": 0.02613022844778105,\n        \"max\": 0.9661755627803613,\n        \"num_unique_values\": 337,\n        \"samples\": [\n          0.07375257004744039,\n          0.24504977075685497,\n          0.06906986347065577\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I showed this to clearly see why I will weight patnets more than research. Because for research less data is available and sometimes the normalized value is 0 for some labels.\n",
        "\n",
        "Next I will check the total counts of each label so I can get some personal insight regarding custom models depending on data availability - previous research we made clearly showed a need for this."
      ],
      "metadata": {
        "id": "dDhmKoVRT8vT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patent_counts_per_label = patents[\"Label\"].value_counts().reset_index()\n",
        "#we count how many times each label appears\n",
        "patent_counts_per_label.columns = [\"Label\", \"Patent_Count\"]\n",
        "\n",
        "#we do the same for research papers\n",
        "research_counts_per_label = research[\"Label\"].value_counts().reset_index()\n",
        "research_counts_per_label.columns = [\"Label\", \"Research_Count\"]\n",
        "\n",
        "#now we just merge and fill any missing vlaues in case they are\n",
        "label_counts = pd.merge(patent_counts_per_label, research_counts_per_label, on=\"Label\", how=\"outer\").fillna(0)\n",
        "label_counts[\"Patent_Count\"] = label_counts[\"Patent_Count\"].astype(int)\n",
        "label_counts[\"Research_Count\"] = label_counts[\"Research_Count\"].astype(int)\n",
        "label_counts[\"Total_Count\"] = label_counts[\"Patent_Count\"] + label_counts[\"Research_Count\"]\n",
        "\n",
        "label_counts = label_counts.sort_values(\"Total_Count\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(label_counts.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "030m2Xly-U0i",
        "outputId": "f956513a-0d58-4407-83c8-63c10ca366f0"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              Label  Patent_Count  Research_Count  Total_Count\n",
            "                  quantum computing          6216            4707        10923\n",
            "     quantum computing applications          5256            2610         7866\n",
            "               quantum optimization          4495            2035         6530\n",
            "                   quantum hardware          4636             420         5056\n",
            "               quantum cryptography          2948            1820         4768\n",
            "quantum computing hardware (hybrid)          3531            1020         4551\n",
            "                    quantum sensing          3685             438         4123\n",
            "             quantum security tools          2721             783         3504\n",
            "                 quantum algorithms          1056            1724         2780\n",
            "                    quantum control          2135             551         2686\n",
            "           quantum machine learning          1399            1284         2683\n",
            "           quantum error correction           810            1612         2422\n",
            "           quantum computing theory           115            1971         2086\n",
            "              quantum communication          1329             680         2009\n",
            "           quantum image processing           968             138         1106\n",
            "                 quantum simulation           415             514          929\n",
            "          quantum signal processing           797             127          924\n",
            "           quantum error mitigation           354             553          907\n",
            "                  quantum coherence           267             595          862\n",
            "      quantum distributed computing           648              83          731\n",
            "            quantum data structures           523              19          542\n",
            "           quantum state tomography           352             175          527\n",
            "                quantum compilation           309             195          504\n",
            "                 quantum conversion           475               1          476\n",
            "            quantum computing in ai            27             194          221\n",
            "             quantum software tools           114              84          198\n",
            "         quantum information theory            16             138          154\n",
            "                  quantum metrology            58              72          130\n",
            "                quantum logic gates           125               1          126\n",
            "        quantum visualization tools            83              17          100\n",
            "             quantum thermodynamics            26              65           91\n",
            "            quantum resource theory            43              32           75\n",
            "     quantum reinforcement learning            60               9           69\n",
            "      quantum computing foundations             0              66           66\n",
            "   quantum computational complexity             1              57           58\n",
            "         quantum noise spectroscopy            39              15           54\n",
            "              quantum surface codes            41               8           49\n",
            "        quantum fidelity estimation            31               1           32\n",
            "      quantum workforce development             2              28           30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "32hPZqSA2hB3"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will hard code this rules to define which order of the model we need to use.\n",
        "\n",
        "I did some tesing before and order 5 gave best results to maxiumum quantity of data. To less data even order 1 (linear regresion model) can obtain smallest RMSE on validation set (last 2 yers of data)."
      ],
      "metadata": {
        "id": "zR2sIHTUbWMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_degree(total_count):\n",
        "    if total_count >= 8000:\n",
        "        return 5\n",
        "    elif total_count >= 2000:\n",
        "        return 3\n",
        "    elif total_count >= 1000:\n",
        "        return 2\n",
        "    else:\n",
        "        return 1"
      ],
      "metadata": {
        "id": "xVFvjeEe_n2p"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "metadata": {
        "id": "vqynyeSwADLS"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the next step is to prepare the training. We apply our function from before to determine firest which order of the model we want to use.\n",
        "\n",
        "In terms of training first we will use all data from 2017-2022 for training and 2023 2024 for **validation**.\n",
        "\n",
        "Latest years of data are more menanigful and represent also a higher curve so it will be smart to actually use all data available for training again, after we check on validation which model to pick.\n",
        "\n",
        "Why we used ridge regularization is explained and detailed in the previous research we made - but i n general to avoid overfitting because we dont have much data, but in the same time it s enough."
      ],
      "metadata": {
        "id": "autybhXhcWFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(label_name, alpha, optimism_factor):\n",
        "\n",
        "    row = label_counts[label_counts[\"Label\"] == label_name]\n",
        "    if row.empty:\n",
        "        print(f\"Label not found: {label_name}\")\n",
        "        return\n",
        "    total_count = row[\"Total_Count\"].values[0]\n",
        "    degree = determine_degree(total_count)\n",
        "    #with this we just establish the degree we use for the polinomial\n",
        "\n",
        "    df = combined[combined[\"Label\"] == label_name][[\"Year\", \"WeightedScore\"]].copy()\n",
        "    df = df[(df[\"Year\"] >= 2017) & (df[\"Year\"] <= 2024)]\n",
        "\n",
        "    #we do the split as discuseed before\n",
        "    train_df = df[df[\"Year\"] <= 2022]\n",
        "    val_df = df[df[\"Year\"] > 2022]\n",
        "\n",
        "    X_train = train_df[\"Year\"].values.reshape(-1, 1)\n",
        "    y_train = train_df[\"WeightedScore\"].values\n",
        "    X_val = val_df[\"Year\"].values.reshape(-1, 1)\n",
        "    y_val = val_df[\"WeightedScore\"].values\n",
        "\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    X_train_poly = poly.fit_transform(X_train)\n",
        "    X_val_poly = poly.transform(X_val)\n",
        "\n",
        "    year_weights = np.linspace(1.0, 2.0, len(y_train))\n",
        "    model = Ridge(alpha=alpha)\n",
        "    #we apply the reglularization\n",
        "    model.fit(X_train_poly, y_train, sample_weight=year_weights)\n",
        "    val_pred = model.predict(X_val_poly)\n",
        "\n",
        "    rmse = mean_squared_error(y_val, val_pred) ** 0.5\n",
        "\n",
        "\n",
        "#we keep those only now fvor testing and exploration in the app gthose will be behind the hood\n",
        "    print(f\"\\nLabel: {label_name} (Degree={degree})\")\n",
        "    print(f\" Validation RMSE (2023â€“2024): {rmse:.4f}\")\n",
        "    print(\"True vs Predicted (Validation):\")\n",
        "    for year, true, pred in zip(X_val.flatten(), y_val, val_pred):\n",
        "        print(f\"   {year}: true={true:.4f} | pred={pred:.4f}\")\n",
        "\n",
        "    #we retrain on the full data\n",
        "    X_full = df[\"Year\"].values.reshape(-1, 1)\n",
        "    y_full = df[\"WeightedScore\"].values\n",
        "    X_full_poly = poly.fit_transform(X_full)\n",
        "\n",
        "    full_weights = np.linspace(1.0, 2.0, len(y_full))\n",
        "    #this gives more importance to recent years\n",
        "    model.fit(X_full_poly, y_full, sample_weight=full_weights)\n",
        "\n",
        "    #we make our predictions\n",
        "    X_future = np.arange(2025, 2029).reshape(-1, 1)\n",
        "    X_future_poly = poly.transform(X_future)\n",
        "    future_preds = model.predict(X_future_poly)\n",
        "\n",
        "    #because I ve seen the model understimate a bit all the predictions on the val set.\n",
        "    #by looking at the quantum market from the past this is not so representable\n",
        "    #so i will artifically boost by 5% the predicted values\n",
        "    future_preds = future_preds * optimism_factor\n",
        "\n",
        "   #here we will probably append al data not ust 2024\n",
        "    last_val_2024 = df[df[\"Year\"] == 2024][\"WeightedScore\"].values[0]\n",
        "    all_years = np.append([2024], X_future.flatten())\n",
        "    all_scores = np.append([last_val_2024], future_preds)\n",
        "\n",
        "\n",
        "    print(\"\\Future Predictions & % Growth vs 2024:\")\n",
        "    baseline_2024 = all_scores[0]\n",
        "    for i in range(1, len(all_years)):\n",
        "       curr_score = all_scores[i]\n",
        "       growth = ((curr_score - baseline_2024) / baseline_2024) * 100 if baseline_2024 != 0 else np.nan\n",
        "       print(f\"   {all_years[i]}: score={curr_score:.4f} | growth vs 2024={growth:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9qVPbNZ8E_fc"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we imput the weight and our hyperparameter from the **RIDGE REGULARIZATION** for testing wise."
      ],
      "metadata": {
        "id": "bbSxeDwtbwMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(\"quantum error correction\", alpha=0.1, optimism_factor=1.05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arjIaFL-2yRx",
        "outputId": "c055725c-53bf-4f49-9628-6f2fc8ba1985"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”Ž Label: quantum error correction (Degree=3)\n",
            "âœ… Validation RMSE (2023â€“2024): 0.0548\n",
            "ðŸ“Š True vs Predicted (Validation):\n",
            "   2023: true=0.2338 | pred=0.1892\n",
            "   2024: true=0.2761 | pred=0.2127\n",
            "\n",
            "ðŸ“ˆ Future Predictions & % Growth vs 2024:\n",
            "   2025: score=0.3486 | growth vs 2024=26.27%\n",
            "   2026: score=0.4154 | growth vs 2024=50.45%\n",
            "   2027: score=0.4894 | growth vs 2024=77.24%\n",
            "   2028: score=0.5706 | growth vs 2024=106.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "go3Zg7IpEQj_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}